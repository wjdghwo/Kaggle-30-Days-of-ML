{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bayesian Optimization_LGBM",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqp00AXlQajB"
      },
      "source": [
        "# Bayesian Optimization\n",
        "\n",
        "Bayesian optimization is a sequential design strategy for global optimization of black-box functions that does not assume any functional forms. It is usually employed to optimize expensive-to-evaluate functions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE-4wbOGSR7s"
      },
      "source": [
        "General properties of Bayesian optimization methods:\n",
        "1. It is a sequential approach. The calculations are not parallelized.\n",
        "2. Do not use the derivative of the objective function. [Appropriate for cases where the derivative is unknownly discrete.\n",
        "Depending on the problem, the derivative may not be defined.\n",
        "Of course, even if a derivative is defined, it can also be applied when it is complicated to calculate. In this case, automatic gradient may be used.]\n",
        "3. Use machine learning methods to predict where there is a better year. (surrogate model) [using artificial intelligence]\n",
        "4. Various models are possible. In addition, results can change sensitively to model selection.\n",
        "5. It is known as an appropriate method for situations where too many objective function calculations cannot be done.\n",
        "  - That is, if the calculation is too high.\n",
        "In other words, it is an optimal method when the cost of creating a surrogate model with machine learning is very low.\n",
        "(However, too much data can make a problem.\n",
        "Problems that are proportional to three wins in the number of data arise. This is the complexity associated with the inverse matrix calculation.\n",
        "  - How much time is spent calculating the objective function? The time it takes to achieve expectations should be directly compared.\n",
        "6. A general optimization algorithm that can be used when the objective function has noise.\n",
        "7. Machine learning methods are continuously available when additional data is reinforced.\n",
        "\n",
        "\n",
        "https://github.com/fmfn/BayesianOptimization\n",
        "\n",
        "\n",
        "- It should be noted that the use is different from that of a typical local minimization algorithm.\n",
        "- For example, traditional local minimization algorithms are still better for very simple function local minimization. [Nelder-Mead]\n",
        "- If the derivative of the objective function is known analytically, traditional computational methods should be used. [BFGS]\n",
        "- The machine learning method is to use when things are more twisted.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxlXTMPnQajC"
      },
      "source": [
        "\n",
        "\n",
        "<img src =\"https://blog.kakaocdn.net/dn/c5AeYX/btqNqC6y46P/yCsuigpZvzKbDUK6dHZg51/img.png\" width=\"500\" height=\"600\"><img>\n",
        "\n",
        "\n",
        "\n",
        "Here, we will use this technique to find the optimal hyper-parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FB88GQIQajF"
      },
      "source": [
        "## Pre-Modeling Operations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY9q-GtXQajG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6f9ce6-d927-4c79-e805-85a2c0badfb0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import seaborn as sns\n",
        "plt.style.use('fivethirtyeight')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "from tqdm import tnrange, tqdm_notebook, notebook, tqdm\n",
        "import time\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import GridSearchCV, cross_validate\n",
        "import sklearn as preprocessing\n",
        "from sklearn.metrics import *"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoDd7R1IQajK"
      },
      "source": [
        "path = '/content/gdrive/MyDrive/kaggle/'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAGzq4F_QajN"
      },
      "source": [
        "train = pd.read_csv(path + 'train.csv')\n",
        "test = pd.read_csv(path + 'test.csv')\n",
        "submission = pd.read_csv(path + 'sample_submission.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUzxYuTJQajR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a160699d-7f15-4481-f246-556cbf5dbdb6"
      },
      "source": [
        "print(train.shape)\n",
        "print(test.shape)\n",
        "print(submission.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300000, 26)\n",
            "(200000, 25)\n",
            "(200000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMXZo0fYgsh4"
      },
      "source": [
        "train = train.iloc[:,1:]\n",
        "test = test.iloc[:,1:]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54OAFdVFgJIL"
      },
      "source": [
        "encoder = preprocessing.LabelEncoder()\n",
        "train_label = train.copy()\n",
        "test_label = test.copy()\n",
        "\n",
        "for i in range(10):\n",
        "    train_label.iloc[:,i] = encoder.fit_transform(train.iloc[:,i])\n",
        "    test_label.iloc[:,i] = encoder.transform(test.iloc[:,i])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z4U_7aZQajU"
      },
      "source": [
        "X_label=train_label.drop('target',axis=1)\n",
        "y=train['target']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-YYZS4VQaj9"
      },
      "source": [
        "## Modeling (Bayesian Optimization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjl5h97WsAIR"
      },
      "source": [
        "- First, find heavy parameters such as `n_estimators` and `learn_rate` using GridSearchCV first.\n",
        "\n",
        "- For time problems, set the parameter to a low value and n_estimators are fixed to a value of 50.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UHv--Mh1I_X",
        "outputId": "9819b2b8-5bdb-4781-f684-0de2054c55e7"
      },
      "source": [
        "learn_rate=[0.05,0.3,0.5,0.9]\n",
        "max_depth=[5,10,15,20]\n",
        "\n",
        "hyper={'learning_rate':learn_rate,'max_depth':max_depth}\n",
        "gd=GridSearchCV(estimator=LGBMRegressor(n_estimators=50, n_jobs=-1),param_grid=hyper,verbose=True, n_jobs=-1, cv=3, scoring='neg_root_mean_squared_error')\n",
        "gd.fit(X_label,y)\n",
        "print(gd.best_score_)\n",
        "print(gd.best_estimator_)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  1.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-0.7250238851106058\n",
            "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
            "              importance_type='split', learning_rate=0.3, max_depth=20,\n",
            "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
            "              n_estimators=50, n_jobs=-1, num_leaves=31, objective=None,\n",
            "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZLOfBMiQaj-"
      },
      "source": [
        "  <br/>\n",
        "\n",
        "We will proceed with modeling by applying the Bayesian optimization method during Hyperparameter Optimization, which is a field of AutoML.\n",
        "\n",
        "Except for the model ensemble, we will calculate the optimal result value with a single model. The model to use is LGBM.\n",
        "\n",
        "For bayesian-optimization to be used in a Python environment, you must install the package. You can install it with the pip command.\n",
        "\n",
        "- bayesian-optimization 1.2.0 [link](https://pypi.org/project/bayesian-optimization/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBRj42iJRQ54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5daa091-1a59-4a37-a2ec-58d17a1d482c"
      },
      "source": [
        "!pip install bayesian-optimization"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian-optimization-1.2.0.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.1)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-py3-none-any.whl size=11685 sha256=0c861c94b30437cf01203bc027053b3a5b665be6b4c9c5fe4d6aa8edc4adb63a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/9b/71/f127d694e02eb40bcf18c7ae9613b88a6be4470f57a8528c5b\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rbTWV6-Qaj_"
      },
      "source": [
        "The 'bayes_opt' module is downloaded to your environment and the installation is complete.\n",
        "\n",
        "<br/>\n",
        "\n",
        "I will import the required package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLkC_RDio9oG"
      },
      "source": [
        "from bayes_opt import BayesianOptimization"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0BtS2dpQakB"
      },
      "source": [
        "The following must create a purpose function: The objective function is a performance function of LGBMRegressor that has a combination of parameters in the model as an input value. Since the performance evaluation is RMSE, it returns the score value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLKPBP1OQakE"
      },
      "source": [
        "# create purpose function\n",
        "def lgbm_cv(learning_rate, n_estimators, max_depth, num_leaves, subsample, min_child_weight, colsample_bytree, max_bin, reg_alpha, reg_lambda):\n",
        "    model = LGBMRegressor(learning_rate = learning_rate,\n",
        "                                n_estimators = int(n_estimators),\n",
        "                                num_leaves = int(round(num_leaves)),\n",
        "                                max_depth = int(round(max_depth)),\n",
        "                                n_jobs = -1,\n",
        "                                random_state = 0,\n",
        "                                subsample = max(subsample, 0),\n",
        "                                min_child_weight = int(round(min_child_weight)),\n",
        "                                colsample_bytree = colsample_bytree,\n",
        "                                max_bin = int(round(max_bin)),\n",
        "                                reg_alpha = max(reg_alpha, 0),\n",
        "                                reg_lambda = max(reg_lambda, 0)\n",
        "                               )\n",
        "    scores = cross_validate(model, X_label, y, cv=5, n_jobs = -1, scoring='neg_root_mean_squared_error')\n",
        "    return np.mean(scores['test_score'])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dft__fUfQakI"
      },
      "source": [
        "Arguments for functions are parameters of the model. Enter the parameter that you want to explore the optimal value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fhb8C3lNQakI"
      },
      "source": [
        "I composed the combination of 10 parameters in total.\n",
        "\n",
        "\n",
        "`learning_rate` and `max_depth`, `n_estimators` are set to a narrow range that does not deviate significantly from the parameters found earlier. And I set the remaining parameters to a wide range. `int(round())` sets for parameters with int values, and `max` and `min` functions for parameters with fixed maximum and minimum values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imPwwKCNQakJ"
      },
      "source": [
        "`cross_validate`is a function that calculates the score.\n",
        "It is common to use the `cross_val_score` method when using a single evaluation index or the `make_scorer` method when using multiple indicators. We will use `cross_val_score` because there is a competition evaluation index.\n",
        "\n",
        "The parameter cv value was specified as 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-bR-k3cQakJ"
      },
      "source": [
        "\n",
        "The following sets the input value, i.e., the navigation interval for the parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmGTbF8UQakK"
      },
      "source": [
        "# Interval to be explored for input values\n",
        "pbounds = {'learning_rate': (0.005, 0.5),\n",
        "           'n_estimators': (30, 80),\n",
        "           'max_depth': (15, 50),\n",
        "           'num_leaves': (0, 100),\n",
        "           'subsample': (0, 0.99),\n",
        "           'min_child_weight' : (0, 100),\n",
        "           'colsample_bytree': (0, 0.99),\n",
        "           'max_bin': (0, 1000),\n",
        "           'reg_alpha': (0, 10),\n",
        "           'reg_lambda' : (0, 10)\n",
        "          }"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm71F22xQakO"
      },
      "source": [
        "The navigation range of the parameters was set by referring to the model-specific descriptive materials. I will omit the detailed description of the parameter.\n",
        "\n",
        "\n",
        "The following creates an object:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRSrmNhJQakO"
      },
      "source": [
        "lgbmBO = BayesianOptimization(f = lgbm_cv, pbounds = pbounds, verbose = 2, random_state = 0)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_uzaMzeQakR"
      },
      "source": [
        "The first factor is the objective function f, and pbounds refer to the navigation interval of the input value. Random seed is set to zero.\n",
        "\n",
        "<br/>\n",
        "\n",
        "Let's do Bayesian Optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOzVvI_XQakR"
      },
      "source": [
        "`init_points` is the number of first-time searches. The calculation proceeds by sampling the input value by `init_points` within the interval set in pbound. `n_iter` is the number of operations. Therefore, you will perform 25 times in total.\n",
        "\n",
        "I will set acq to EI. xi is an argument that controls the intensity of the expansion-exposition, which typically increases the expansion by setting it to 0.01.\n",
        "\n",
        "The results of the operation are as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCSZDzkKQakS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be5006f8-8a92-4ed0-dcee-42fad7fac1db"
      },
      "source": [
        "lgbmBO.maximize(init_points=5, n_iter = 20, acq='ei', xi=0.01)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | colsam... | learni... |  max_bin  | max_depth | min_ch... | n_esti... | num_le... | reg_alpha | reg_la... | subsample |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.7223  \u001b[0m | \u001b[0m 0.5433  \u001b[0m | \u001b[0m 0.359   \u001b[0m | \u001b[0m 602.8   \u001b[0m | \u001b[0m 34.07   \u001b[0m | \u001b[0m 42.37   \u001b[0m | \u001b[0m 62.29   \u001b[0m | \u001b[0m 43.76   \u001b[0m | \u001b[0m 8.918   \u001b[0m | \u001b[0m 9.637   \u001b[0m | \u001b[0m 0.3796  \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.7386  \u001b[0m | \u001b[0m 0.7838  \u001b[0m | \u001b[0m 0.2668  \u001b[0m | \u001b[0m 568.0   \u001b[0m | \u001b[0m 47.4    \u001b[0m | \u001b[0m 7.104   \u001b[0m | \u001b[0m 34.36   \u001b[0m | \u001b[0m 2.022   \u001b[0m | \u001b[0m 8.326   \u001b[0m | \u001b[0m 7.782   \u001b[0m | \u001b[0m 0.8613  \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.7227  \u001b[0m | \u001b[0m 0.9688  \u001b[0m | \u001b[0m 0.4006  \u001b[0m | \u001b[0m 461.5   \u001b[0m | \u001b[0m 42.32   \u001b[0m | \u001b[0m 11.83   \u001b[0m | \u001b[0m 62.0    \u001b[0m | \u001b[0m 14.34   \u001b[0m | \u001b[0m 9.447   \u001b[0m | \u001b[0m 5.218   \u001b[0m | \u001b[0m 0.4105  \u001b[0m |\n",
            "| \u001b[95m 4       \u001b[0m | \u001b[95m-0.722   \u001b[0m | \u001b[95m 0.2619  \u001b[0m | \u001b[95m 0.3882  \u001b[0m | \u001b[95m 456.2   \u001b[0m | \u001b[95m 34.9    \u001b[0m | \u001b[95m 1.879   \u001b[0m | \u001b[95m 60.88   \u001b[0m | \u001b[95m 61.21   \u001b[0m | \u001b[95m 6.169   \u001b[0m | \u001b[95m 9.437   \u001b[0m | \u001b[95m 0.675   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.7227  \u001b[0m | \u001b[0m 0.3559  \u001b[0m | \u001b[0m 0.2213  \u001b[0m | \u001b[0m 697.6   \u001b[0m | \u001b[0m 17.11   \u001b[0m | \u001b[0m 66.68   \u001b[0m | \u001b[0m 63.53   \u001b[0m | \u001b[0m 21.04   \u001b[0m | \u001b[0m 1.289   \u001b[0m | \u001b[0m 3.154   \u001b[0m | \u001b[0m 0.3601  \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.7252  \u001b[0m | \u001b[0m 0.2394  \u001b[0m | \u001b[0m 0.2689  \u001b[0m | \u001b[0m 41.45   \u001b[0m | \u001b[0m 20.65   \u001b[0m | \u001b[0m 99.84   \u001b[0m | \u001b[0m 73.24   \u001b[0m | \u001b[0m 89.97   \u001b[0m | \u001b[0m 1.683   \u001b[0m | \u001b[0m 6.654   \u001b[0m | \u001b[0m 0.08468 \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.7276  \u001b[0m | \u001b[0m 0.4081  \u001b[0m | \u001b[0m 0.05234 \u001b[0m | \u001b[0m 465.6   \u001b[0m | \u001b[0m 24.11   \u001b[0m | \u001b[0m 99.15   \u001b[0m | \u001b[0m 79.39   \u001b[0m | \u001b[0m 80.17   \u001b[0m | \u001b[0m 5.986   \u001b[0m | \u001b[0m 3.435   \u001b[0m | \u001b[0m 0.05345 \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.7287  \u001b[0m | \u001b[0m 0.7359  \u001b[0m | \u001b[0m 0.06005 \u001b[0m | \u001b[0m 463.9   \u001b[0m | \u001b[0m 42.37   \u001b[0m | \u001b[0m 11.47   \u001b[0m | \u001b[0m 69.04   \u001b[0m | \u001b[0m 59.02   \u001b[0m | \u001b[0m 9.861   \u001b[0m | \u001b[0m 1.4     \u001b[0m | \u001b[0m 0.3318  \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.732   \u001b[0m | \u001b[0m 0.7961  \u001b[0m | \u001b[0m 0.1985  \u001b[0m | \u001b[0m 10.01   \u001b[0m | \u001b[0m 21.87   \u001b[0m | \u001b[0m 3.894   \u001b[0m | \u001b[0m 79.66   \u001b[0m | \u001b[0m 14.9    \u001b[0m | \u001b[0m 5.428   \u001b[0m | \u001b[0m 9.551   \u001b[0m | \u001b[0m 0.2641  \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.7229  \u001b[0m | \u001b[0m 0.1234  \u001b[0m | \u001b[0m 0.2832  \u001b[0m | \u001b[0m 1e+03   \u001b[0m | \u001b[0m 19.71   \u001b[0m | \u001b[0m 1.384   \u001b[0m | \u001b[0m 78.61   \u001b[0m | \u001b[0m 18.67   \u001b[0m | \u001b[0m 5.012   \u001b[0m | \u001b[0m 4.217   \u001b[0m | \u001b[0m 0.698   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.7238  \u001b[0m | \u001b[0m 0.4806  \u001b[0m | \u001b[0m 0.4149  \u001b[0m | \u001b[0m 618.7   \u001b[0m | \u001b[0m 17.94   \u001b[0m | \u001b[0m 8.852   \u001b[0m | \u001b[0m 78.77   \u001b[0m | \u001b[0m 5.932   \u001b[0m | \u001b[0m 7.009   \u001b[0m | \u001b[0m 9.425   \u001b[0m | \u001b[0m 0.4542  \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.7299  \u001b[0m | \u001b[0m 0.4488  \u001b[0m | \u001b[0m 0.485   \u001b[0m | \u001b[0m 943.4   \u001b[0m | \u001b[0m 36.76   \u001b[0m | \u001b[0m 95.41   \u001b[0m | \u001b[0m 73.01   \u001b[0m | \u001b[0m 99.93   \u001b[0m | \u001b[0m 5.01    \u001b[0m | \u001b[0m 7.813   \u001b[0m | \u001b[0m 0.7139  \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.7326  \u001b[0m | \u001b[0m 0.3958  \u001b[0m | \u001b[0m 0.1361  \u001b[0m | \u001b[0m 166.4   \u001b[0m | \u001b[0m 48.47   \u001b[0m | \u001b[0m 95.93   \u001b[0m | \u001b[0m 63.07   \u001b[0m | \u001b[0m 5.255   \u001b[0m | \u001b[0m 4.283   \u001b[0m | \u001b[0m 7.607   \u001b[0m | \u001b[0m 0.8366  \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.7389  \u001b[0m | \u001b[0m 0.3687  \u001b[0m | \u001b[0m 0.04347 \u001b[0m | \u001b[0m 459.0   \u001b[0m | \u001b[0m 37.5    \u001b[0m | \u001b[0m 14.37   \u001b[0m | \u001b[0m 64.01   \u001b[0m | \u001b[0m 5.496   \u001b[0m | \u001b[0m 7.336   \u001b[0m | \u001b[0m 3.855   \u001b[0m | \u001b[0m 0.2097  \u001b[0m |\n",
            "| \u001b[95m 15      \u001b[0m | \u001b[95m-0.7214  \u001b[0m | \u001b[95m 0.2517  \u001b[0m | \u001b[95m 0.3339  \u001b[0m | \u001b[95m 316.7   \u001b[0m | \u001b[95m 20.55   \u001b[0m | \u001b[95m 84.36   \u001b[0m | \u001b[95m 65.56   \u001b[0m | \u001b[95m 35.53   \u001b[0m | \u001b[95m 3.214   \u001b[0m | \u001b[95m 8.982   \u001b[0m | \u001b[95m 0.5795  \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.744   \u001b[0m | \u001b[0m 0.6674  \u001b[0m | \u001b[0m 0.01638 \u001b[0m | \u001b[0m 879.5   \u001b[0m | \u001b[0m 36.83   \u001b[0m | \u001b[0m 89.66   \u001b[0m | \u001b[0m 73.61   \u001b[0m | \u001b[0m 1.957   \u001b[0m | \u001b[0m 4.534   \u001b[0m | \u001b[0m 9.756   \u001b[0m | \u001b[0m 0.6539  \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.7277  \u001b[0m | \u001b[0m 0.9331  \u001b[0m | \u001b[0m 0.3487  \u001b[0m | \u001b[0m 68.64   \u001b[0m | \u001b[0m 47.69   \u001b[0m | \u001b[0m 6.146   \u001b[0m | \u001b[0m 42.15   \u001b[0m | \u001b[0m 95.77   \u001b[0m | \u001b[0m 5.953   \u001b[0m | \u001b[0m 7.627   \u001b[0m | \u001b[0m 0.5731  \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.7218  \u001b[0m | \u001b[0m 0.3631  \u001b[0m | \u001b[0m 0.2886  \u001b[0m | \u001b[0m 810.0   \u001b[0m | \u001b[0m 16.47   \u001b[0m | \u001b[0m 0.05297 \u001b[0m | \u001b[0m 66.48   \u001b[0m | \u001b[0m 96.3    \u001b[0m | \u001b[0m 9.839   \u001b[0m | \u001b[0m 9.597   \u001b[0m | \u001b[0m 0.2124  \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.7253  \u001b[0m | \u001b[0m 0.5787  \u001b[0m | \u001b[0m 0.46    \u001b[0m | \u001b[0m 654.8   \u001b[0m | \u001b[0m 23.06   \u001b[0m | \u001b[0m 19.0    \u001b[0m | \u001b[0m 48.24   \u001b[0m | \u001b[0m 59.44   \u001b[0m | \u001b[0m 2.668   \u001b[0m | \u001b[0m 9.025   \u001b[0m | \u001b[0m 0.1694  \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.7267  \u001b[0m | \u001b[0m 0.9255  \u001b[0m | \u001b[0m 0.117   \u001b[0m | \u001b[0m 341.2   \u001b[0m | \u001b[0m 47.98   \u001b[0m | \u001b[0m 73.06   \u001b[0m | \u001b[0m 45.5    \u001b[0m | \u001b[0m 79.58   \u001b[0m | \u001b[0m 9.314   \u001b[0m | \u001b[0m 9.207   \u001b[0m | \u001b[0m 0.7562  \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.7224  \u001b[0m | \u001b[0m 0.8454  \u001b[0m | \u001b[0m 0.2454  \u001b[0m | \u001b[0m 711.5   \u001b[0m | \u001b[0m 17.52   \u001b[0m | \u001b[0m 99.37   \u001b[0m | \u001b[0m 73.38   \u001b[0m | \u001b[0m 61.46   \u001b[0m | \u001b[0m 7.956   \u001b[0m | \u001b[0m 8.829   \u001b[0m | \u001b[0m 0.5037  \u001b[0m |\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.725   \u001b[0m | \u001b[0m 0.3292  \u001b[0m | \u001b[0m 0.1965  \u001b[0m | \u001b[0m 995.9   \u001b[0m | \u001b[0m 15.44   \u001b[0m | \u001b[0m 1.396   \u001b[0m | \u001b[0m 35.69   \u001b[0m | \u001b[0m 85.85   \u001b[0m | \u001b[0m 6.983   \u001b[0m | \u001b[0m 9.285   \u001b[0m | \u001b[0m 0.05916 \u001b[0m |\n",
            "| \u001b[95m 23      \u001b[0m | \u001b[95m-0.7206  \u001b[0m | \u001b[95m 0.2111  \u001b[0m | \u001b[95m 0.2037  \u001b[0m | \u001b[95m 388.3   \u001b[0m | \u001b[95m 48.64   \u001b[0m | \u001b[95m 77.07   \u001b[0m | \u001b[95m 79.73   \u001b[0m | \u001b[95m 58.4    \u001b[0m | \u001b[95m 9.357   \u001b[0m | \u001b[95m 9.875   \u001b[0m | \u001b[95m 0.8165  \u001b[0m |\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.7322  \u001b[0m | \u001b[0m 0.1838  \u001b[0m | \u001b[0m 0.3529  \u001b[0m | \u001b[0m 13.87   \u001b[0m | \u001b[0m 17.85   \u001b[0m | \u001b[0m 66.41   \u001b[0m | \u001b[0m 30.7    \u001b[0m | \u001b[0m 14.23   \u001b[0m | \u001b[0m 4.59    \u001b[0m | \u001b[0m 8.683   \u001b[0m | \u001b[0m 0.104   \u001b[0m |\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.7344  \u001b[0m | \u001b[0m 0.9074  \u001b[0m | \u001b[0m 0.05046 \u001b[0m | \u001b[0m 190.5   \u001b[0m | \u001b[0m 16.68   \u001b[0m | \u001b[0m 17.19   \u001b[0m | \u001b[0m 35.41   \u001b[0m | \u001b[0m 64.45   \u001b[0m | \u001b[0m 9.684   \u001b[0m | \u001b[0m 9.449   \u001b[0m | \u001b[0m 0.8499  \u001b[0m |\n",
            "=================================================================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlo4c3HtQakU"
      },
      "source": [
        "The `target` value corresponds to the RMSE score as the return value of the objective function. I was able to get a value of about 0.721.\n",
        "\n",
        "Although there is no significant improvement in performance, estimating a small number of parameter combinations or proceeding with model ensembles can result in better scores.\n",
        "\n",
        "<br/>\n",
        "\n",
        "The parameter values calculated are as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14Ak_D4PrFLi",
        "outputId": "82c343bc-6203-4014-cc21-465d07c7a915"
      },
      "source": [
        "lgbmBO.max"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'params': {'colsample_bytree': 0.21106978103490293,\n",
              "  'learning_rate': 0.20370811972451633,\n",
              "  'max_bin': 388.32866754216286,\n",
              "  'max_depth': 48.637200464467874,\n",
              "  'min_child_weight': 77.06806238233416,\n",
              "  'n_estimators': 79.72581709966855,\n",
              "  'num_leaves': 58.4002115286548,\n",
              "  'reg_alpha': 9.356747820775828,\n",
              "  'reg_lambda': 9.874741430024695,\n",
              "  'subsample': 0.8165349055304533},\n",
              " 'target': -0.7205944791230456}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky9trD7OQakX"
      },
      "source": [
        "#파라미터 적용\n",
        "fit_lgbm = lgbm.LGBMRegressor(learning_rate=lgbmBO.max['params']['learning_rate'],\n",
        "                               n_estimators = int(round(lgbmBO.max['params']['n_estimators'])),\n",
        "                               num_leaves = int(round(lgbmBO.max['params']['num_leaves'])),\n",
        "                               max_depth = int(round(lgbmBO.max['params']['max_depth'])),\n",
        "                               max_bin = int(round(lgbmBO.max['params']['max_bin'])),\n",
        "                               min_child_weight = int(round(lgbmBO.max['params']['min_child_weight'])),\n",
        "                               colsample_bytree=lgbmBO.max['params']['colsample_bytree'],\n",
        "                               subsample = lgbmBO.max['params']['subsample'],\n",
        "                               reg_alpha = lgbmBO.max['params']['reg_alpha'],\n",
        "                               reg_lambda = lgbmBO.max['params']['reg_lambda']\n",
        "                               )"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mq42lE1n0yc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7432a6a7-aca3-47b8-85be-b73d00c149d6"
      },
      "source": [
        "fit_lgbm"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(boosting_type='gbdt', class_weight=None,\n",
              "              colsample_bytree=0.21106978103490293, importance_type='split',\n",
              "              learning_rate=0.20370811972451633, max_bin=388, max_depth=49,\n",
              "              min_child_samples=20, min_child_weight=77, min_split_gain=0.0,\n",
              "              n_estimators=80, n_jobs=-1, num_leaves=58, objective=None,\n",
              "              random_state=None, reg_alpha=9.356747820775828,\n",
              "              reg_lambda=9.874741430024695, silent=True,\n",
              "              subsample=0.8165349055304533, subsample_for_bin=200000,\n",
              "              subsample_freq=0)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxxUiYcRQakZ"
      },
      "source": [
        "model = fit_lgbm.fit(X_label,y)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsS3sTHnQakc"
      },
      "source": [
        "The model operation is complete."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjV_UktRQakd"
      },
      "source": [
        "## Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ_EMH49Qakf"
      },
      "source": [
        "pred_y = model.predict(test_label)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmYbBcNaQaki"
      },
      "source": [
        "submission['target']=pred_y\n",
        "submission.to_csv('submission_BO.csv')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2jvOVt_Qakl"
      },
      "source": [
        "---\n",
        "Hope this helps. In the previous process, creating a slightly more advanced model through GridSearchCV, estimating combinations with fewer parameters, and ensembling models with good scores will likely lead to greater performance improvements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N70n6rO81l5x"
      },
      "source": [
        "\n",
        "- reference \n",
        "\n",
        "https://www.dacon.io/competitions/official/235647/codeshare/1720\n",
        "\n",
        "http://egloos.zum.com/incredible/v/7479039\n",
        "\n",
        "https://en.wikipedia.org/wiki/Bayesian_optimization"
      ]
    }
  ]
}
